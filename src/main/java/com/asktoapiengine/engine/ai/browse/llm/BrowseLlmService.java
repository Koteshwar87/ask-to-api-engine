package com.asktoapiengine.engine.ai.browse.llm;

import com.asktoapiengine.engine.ai.browse.swagger.ApiOperationDescriptor;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.util.List;

/**
 * BrowseLlmService is the LLM-facing service for the "Browse APIs" use case.
 *
 * Responsibilities:
 *  1. Accept the user's natural language query and the candidate API operations
 *     returned from the RAG layer.
 *  2. Delegate to BrowsePromptBuilder to construct a detailed prompt.
 *  3. Call the LLM through the LlmClient abstraction.
 *
 * This service is fully provider-agnostic:
 *  - The concrete LLM implementation (OpenAI ChatModel, HTTP, Ollama, SparkAssist, etc.)
 *    is selected by Spring via the llm.provider property and injected as LlmClient.
 */
@Slf4j
@Service
@RequiredArgsConstructor
public class BrowseLlmService {

    /**
     * Unified LLM abstraction for the application.
     * The actual provider bean is chosen via llm.provider.
     */
    private final LlmClient llmClient;

    /**
     * Component responsible for building the final browse prompt text.
     */
    private final BrowsePromptBuilder browsePromptBuilder;

    /**
     * Uses the LLM to generate a human-friendly answer that tells the user
     * which API endpoints to call and how to call them.
     *
     * @param userQuery           natural language question about the APIs
     * @param candidateOperations list of Swagger operations retrieved by RAG
     * @return answer generated by the LLM
     */
    public String getBrowseAnswer(String userQuery, List<ApiOperationDescriptor> candidateOperations) {
        log.info("BrowseLlmService: building prompt for LLM browse answer");

        // Build the prompt from user query + candidate operations
        String prompt = browsePromptBuilder.buildPrompt(userQuery, candidateOperations);

        log.info("BrowseLlmService: sending prompt to LlmClient");
        String answer = llmClient.generate(prompt);

        log.info("BrowseLlmService: received answer from LlmClient, length={}",
                answer != null ? answer.length() : 0);

        return answer;
    }
}
